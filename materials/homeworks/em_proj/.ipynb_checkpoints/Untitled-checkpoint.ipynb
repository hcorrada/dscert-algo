{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSA with EM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a word count matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "num_docs = 20\n",
    "num_words = 100\n",
    "num_topics = 3\n",
    "num_words_per_doc = 20\n",
    "\n",
    "\n",
    "def generate_mat(num_docs, num_words, num_topics, num_words_per_doc, p, theta):\n",
    "    mat = np.zeros((num_docs, num_words))\n",
    "    delta = np.zeros((num_docs,num_words,num_topics))\n",
    "    for d in range(num_docs):\n",
    "        nwt = np.random.multinomial(num_words_per_doc, p[d,:])\n",
    "        for t, n in np.ndenumerate(nwt):\n",
    "            delta[d,:,t] = np.random.multinomial(n, theta[t[0],:])\n",
    "            mat[d,:] += delta[d,:,t][0,:]\n",
    "    return mat, delta\n",
    "        \n",
    "def generate_data(num_docs, num_words, num_topics, num_words_per_doc):\n",
    "    p = np.zeros((num_docs, num_topics))\n",
    "    for d in range(num_docs):\n",
    "        t = d % num_topics\n",
    "        p[d,t] = .8\n",
    "        p[d,:t] = .2/(num_topics-1)\n",
    "        p[d,t+1:] = .2/(num_topics-1)\n",
    "        \n",
    "    theta = np.ones((num_topics, num_words))\n",
    "    n_useful_words = 5 * num_topics\n",
    "    \n",
    "    for w in range(n_useful_words):\n",
    "        t = w % num_topics\n",
    "        theta[t,w] = 100.\n",
    "        theta[:t,w] = 10.\n",
    "        theta[t+1:,w] = 10.\n",
    "    for t in range(num_topics):\n",
    "        theta[t,:] = theta[t,:] / np.sum(theta[t,:])\n",
    "        \n",
    "    mat,delta = generate_mat(num_docs, num_words, num_topics, num_words_per_doc, p, theta)\n",
    "    return mat, delta, p, theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1240.5423470157878\n",
      "-1400.6335749277573\n"
     ]
    }
   ],
   "source": [
    "mat, delta,p, theta = generate_data(num_docs,num_words,num_topics,num_words_per_doc)\n",
    "print(get_loglik(mat,p,theta))\n",
    "print(get_qopt(mat,delta,p,theta))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0\n",
      "[4.87804878 0.06097561 0.06097561]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "        -1.11022302e-16,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 0.00000000e+00,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 4.44089210e-16,  0.00000000e+00,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  4.44089210e-16,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma = np.zeros((num_docs,num_words,num_topics))\n",
    "estep(mat, gamma, num_topics, p, theta)\n",
    "print(mat[0,3])\n",
    "print(gamma[0,3,:])\n",
    "mat2=np.sum(gamma,axis=2)\n",
    "mat2-mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8 0.1 0.1]\n",
      "[0.1459854  0.01459854 0.01459854]\n",
      "[0.11678832116788321, 0.0014598540145985403, 0.0014598540145985403]\n",
      "0.11970802919708029\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.97560976, 0.01219512, 0.01219512])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(p[0,:])\n",
    "print(theta[:,0])\n",
    "print([p[0,t]*theta[t,0] for t in range(num_topics)])\n",
    "tmp=p[0,:]*theta[:,0]\n",
    "print(sum(tmp))\n",
    "tmp / sum(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_params(num_docs, num_words, num_topics):\n",
    "    p = np.zeros((num_docs, num_topics))\n",
    "    for d in range(num_docs):\n",
    "        p[d,:] = np.random.dirichlet(np.ones((num_topics)))\n",
    "        \n",
    "    theta = np.zeros((num_topics, num_words))\n",
    "    for t in range(num_topics):\n",
    "        theta[t,:] = np.random.dirichlet(np.ones((num_words)))\n",
    "        \n",
    "    return p, theta\n",
    "\n",
    "def guarded_log(x):\n",
    "    return 0 if x == 0 else np.log(x)\n",
    "\n",
    "def estep(mat, gamma, num_topics, p, theta):\n",
    "    num_docs, num_words = mat.shape\n",
    "    for d in range(num_docs):\n",
    "        for w in range(num_words):\n",
    "            nwd = mat[d,w]\n",
    "            if nwd == 0:\n",
    "                gamma[d,w,:] = 0.\n",
    "                next\n",
    "                \n",
    "            tmp = p[d,:] * theta[:,w]\n",
    "            denom = sum(tmp)\n",
    "            if denom == 0:\n",
    "                gamma[d,w,:] = 0.\n",
    "                next\n",
    "                \n",
    "            gamma[d,w,:] = tmp / denom\n",
    "                    \n",
    "                \n",
    "def mstep(mat, num_topics, gamma):\n",
    "    num_docs, num_words = mat.shape\n",
    "    p = np.zeros((num_docs, num_topics))\n",
    "    \n",
    "    for d in range(num_docs):\n",
    "        s_d = np.sum(gamma[d,:,:],axis=0)\n",
    "        p[d,:] = s_d / np.sum(s_d)\n",
    "        \n",
    "    theta = np.zeros((num_topics, num_words))\n",
    "    \n",
    "    for t in range(num_topics):\n",
    "        s_t = np.sum(gamma[:,:,t], axis=0)\n",
    "        theta[t,:] = s_t / np.sum(s_t)\n",
    "    return p, theta\n",
    "            \n",
    "def get_loglik(mat, p, theta):\n",
    "    num_docs, num_words = mat.shape\n",
    "    num_topics = p.shape[1]\n",
    "    res = 0\n",
    "    for d in range(num_docs):\n",
    "        for w in range(num_words):\n",
    "            nwd = mat[d,w]\n",
    "            if nwd == 0:\n",
    "                next\n",
    "                \n",
    "            tsum = 0\n",
    "            for t in range(num_topics):\n",
    "                tsum += p[d,t] * theta[t,w]\n",
    "            res += nwd * guarded_log(tsum)            \n",
    "    return res\n",
    "    \n",
    "def get_qopt(mat, gamma, p, theta):\n",
    "    num_docs, num_words, num_topics = gamma.shape\n",
    "    res = 0.0\n",
    "    for d in range(num_docs):\n",
    "        for w in range(num_words):\n",
    "            for t in range(num_topics):\n",
    "                res += gamma[d,w,t] * guarded_log(p[d,t])\n",
    "                res += gamma[d,w,t] * guarded_log(theta[t,w])\n",
    "    return res\n",
    "\n",
    "def check_convergence(cur_it, cur_llik, new_llik, max_iter, eps):\n",
    "    return cur_it >= max_iter or np.abs(new_llik - cur_llik) < eps\n",
    "\n",
    "def plsa_em(mat, num_topics=10, max_iter=1000, eps=1e-6):\n",
    "    num_docs, num_words = mat.shape\n",
    "    print_template = \"It: {0:d}, loglik: {1:.5f}, old_q: {2:.5f}, new_q: {3:.5f}\"\n",
    "    p, theta = init_params(num_docs, num_words, num_topics)\n",
    "    gamma = np.zeros((num_docs, num_words, num_topics))\n",
    "    \n",
    "    cur_llik = get_loglik(mat, p, theta)\n",
    "    \n",
    "    i = 0\n",
    "    while True:\n",
    "        estep(mat, gamma, num_topics, p, theta)\n",
    "        old_q = get_qopt(mat, gamma, p, theta)\n",
    "        new_p, new_theta = mstep(mat, num_topics, gamma)\n",
    "        new_llik = get_loglik(mat, new_p, new_theta)\n",
    "        new_q = get_qopt(mat, gamma, new_p, new_theta)\n",
    "        \n",
    "        print(print_template.format(i, new_llik, old_q, new_q))\n",
    "        if check_convergence(i, cur_llik, new_llik, max_iter, eps):\n",
    "            break\n",
    "\n",
    "        i += 1\n",
    "        p, theta = new_p, new_theta\n",
    "    return p, theta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It: 0, loglik: -1852.15851, old_q: -11141.88009, new_q: -10664.92605\n",
      "It: 1, loglik: -1847.16689, old_q: -10849.64736, new_q: -10832.52450\n",
      "It: 2, loglik: -1845.01975, old_q: -10939.82056, new_q: -10932.36720\n",
      "It: 3, loglik: -1843.92420, old_q: -11002.56896, new_q: -10998.64968\n",
      "It: 4, loglik: -1843.30052, old_q: -11048.25060, new_q: -11045.92680\n",
      "It: 5, loglik: -1842.91700, old_q: -11082.90889, new_q: -11081.41073\n",
      "It: 6, loglik: -1842.66715, old_q: -11110.09485, new_q: -11109.06743\n",
      "It: 7, loglik: -1842.49682, old_q: -11131.99165, new_q: -11131.25292\n",
      "It: 8, loglik: -1842.37636, old_q: -11150.00489, new_q: -11149.45358\n",
      "It: 9, loglik: -1842.28850, old_q: -11165.07767, new_q: -11164.65376\n",
      "It: 10, loglik: -1842.22270, old_q: -11177.86587, new_q: -11177.53190\n",
      "It: 11, loglik: -1842.17227, old_q: -11188.84010, new_q: -11188.57167\n",
      "It: 12, loglik: -1842.13284, old_q: -11198.34731, new_q: -11198.12792\n",
      "It: 13, loglik: -1842.10143, old_q: -11206.64942, new_q: -11206.46760\n",
      "It: 14, loglik: -1842.07602, old_q: -11213.94834, new_q: -11213.79587\n",
      "It: 15, loglik: -1842.05515, old_q: -11220.40263, new_q: -11220.27349\n",
      "It: 16, loglik: -1842.03779, old_q: -11226.13885, new_q: -11226.02852\n",
      "It: 17, loglik: -1842.02319, old_q: -11231.25945, new_q: -11231.16451\n",
      "It: 18, loglik: -1842.01079, old_q: -11235.84851, new_q: -11235.76629\n",
      "It: 19, loglik: -1842.00015, old_q: -11239.97573, new_q: -11239.90414\n",
      "It: 20, loglik: -1841.99097, old_q: -11243.69955, new_q: -11243.63692\n"
     ]
    }
   ],
   "source": [
    "p_hat, theta_hat = plsa_em(mat, num_topics=3, max_iter=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8 0.1 0.1]\n",
      "[0.42913359 0.41679339 0.15407302]\n"
     ]
    }
   ],
   "source": [
    "print(p[0,:])\n",
    "print(p_hat[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.1459854 , 0.01459854, 0.01459854, 0.1459854 , 0.01459854,\n",
       "       0.01459854, 0.1459854 , 0.01459854, 0.01459854, 0.1459854 ,\n",
       "       0.01459854, 0.01459854, 0.1459854 , 0.01459854, 0.01459854,\n",
       "       0.00145985, 0.00145985, 0.00145985, 0.00145985, 0.00145985,\n",
       "       0.00145985, 0.00145985, 0.00145985, 0.00145985, 0.00145985,\n",
       "       0.00145985, 0.00145985, 0.00145985, 0.00145985, 0.00145985,\n",
       "       0.00145985, 0.00145985, 0.00145985, 0.00145985, 0.00145985,\n",
       "       0.00145985, 0.00145985, 0.00145985, 0.00145985, 0.00145985,\n",
       "       0.00145985, 0.00145985, 0.00145985, 0.00145985, 0.00145985,\n",
       "       0.00145985, 0.00145985, 0.00145985, 0.00145985, 0.00145985,\n",
       "       0.00145985, 0.00145985, 0.00145985, 0.00145985, 0.00145985,\n",
       "       0.00145985, 0.00145985, 0.00145985, 0.00145985, 0.00145985,\n",
       "       0.00145985, 0.00145985, 0.00145985, 0.00145985, 0.00145985,\n",
       "       0.00145985, 0.00145985, 0.00145985, 0.00145985, 0.00145985,\n",
       "       0.00145985, 0.00145985, 0.00145985, 0.00145985, 0.00145985,\n",
       "       0.00145985, 0.00145985, 0.00145985, 0.00145985, 0.00145985,\n",
       "       0.00145985, 0.00145985, 0.00145985, 0.00145985, 0.00145985,\n",
       "       0.00145985, 0.00145985, 0.00145985, 0.00145985, 0.00145985,\n",
       "       0.00145985, 0.00145985, 0.00145985, 0.00145985, 0.00145985,\n",
       "       0.00145985, 0.00145985, 0.00145985, 0.00145985, 0.00145985])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
